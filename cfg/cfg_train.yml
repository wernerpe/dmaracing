#ripped from ig, change later
seed: -1
clip_observations: 1000.0
clip_actions: 4.0
policy: 
  vf_hid_sizes: [64, 32]
  pi_hid_sizes: [64, 32]
  activation: elu # can be elu, relu, selu, crelu, lrelu, tanh, sigmoid
learn:
  agent_name: dmar
  experiment: exp
  test: False
  resume: 0
  save_interval: 50 # check for potential saves every this many iterations
  print_log: True

  # number of policy updates
  max_iterations: 500

  # training params
  cliprange: 0.2
  ent_coef: 0.00
  nsteps: 32
  noptepochs: 8
  nminibatches: 4 # this is per agent
  optim_stepsize: 1.e-4
  schedule: adaptive # could be adaptive, linear or fixed
  gamma: 0.99
  lam: 0.95
  init_noise_std: 1.0
  desired_kl: 0.01
  log_interval: 1
