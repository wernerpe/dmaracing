test: False
trackRaceStatistics: False #makes sim substantially slower
logBehaviorStatistics: True
sim:
  numEnv: 2048  # 1024
  #number of racing agents per env
  numAgents: 4
  dt: 0.01  # 0.01  # 0.02 #[s] # If using this with TRI dynamics model, this must be 0.02 to match the refresh frequency of the model
  numStates: 7

  #need to overwrite this everytime env gets initialized to the correct number
  #dependent on the lookaheadhorizon length and number of ado cars in an env
  #this is done in get_cfg directly
  numObservations: -1
  numConstantObservations: 10  # 8 #vels, rxy, lxy, [maxvel=8obs], last actions, rank, teamrank(, offtrack time = 9)  [wheels, time, jump] = 7+3
  numConstantObservationsLL: 5  #  5  # goalpos, goalstd, lltime
  numActions: 2
  numActionsHL: 4  # goalpos, goalstd
  collide: 1
  decimation: 10  # 10  # 4
  test_mode: False
  collisionstiffness: 80.0
  filtercollisionstoego: False  # True  # False
  reset_timeout_only: False

  tile_jump_lim: 15

  logBehaviorEvery: 20

model:
  lr: 0.14
  lf: 0.19
  W_coll: 0.35
  L_coll: 0.58
  noise_level: 1.0  # 0.5  # 1.0
  col_decay_time: 0.5
  Iz: 0.03
  max_vel: 4.0  # 3.5  # 5.0  # 3.5
  mass: 3.3
  #gp_noise_scale: 0.01
  Bf: 0.711
  Br: 2.482
  Cf: 1.414
  Cr: 1.343
  Df: 0.892
  Dr: 0.892
  max_steer_rate: 2.1 #rad/s
  vm_noise_scale_ego: 0.1  # 0.30
  vm_noise_scale_ado: 0.5  # 0.5  # 0.3  # 0.3
  lf_noise_scale: 0.02
  lr_noise_scale: 0.02
  steering_offset_noise_scale: 0.03
  gas_noise_scale: [-0.15, 0.05]
  #BLR slip model
  alpha_f_mean: [-0.16356078,  0.23466891,  0.47629134]
  alpha_f_sigma: [[ 0.07033759, -0.0210406 , -0.10337932],
                  [-0.0210406 ,  0.01222755, -0.00317403],
                  [-0.10337932, -0.00317403,  0.52084342]]
  #low level PD controller params
  k_steer: 1.0
  d_steer: 0.1
  k_vel: 1.0 
  d_vel: 0.2
  
viewer:
  width: 1200  # 1200
  height: 1200  # 1200
  width_tb: 600  # 1200
  height_tb: 600  # 1200

  scale: 12.0 #[m/width*px] indicates how wide the window is in pixels
  linethickness: 1
  multiagent: True
  maxAgents: 400
  logEvery: 20

track:
  #https://github.com/openai/gym/blob/master/gym/envs/box2d/car_racing.py
  verbose: False
  seed: 1
  ccw: True
  draw_centerline: False
  track_half_width: 0.6  # 0.63  # 0.7  # 0.6
  track_poly_spacing: 0.15
  
learn:
  steer_ado_with_PPC: True  # True
  iters_ado_with_PPC: 200  # 150  # 500  # 5000
  ppc_prob_itr_ini: 200  # 50  # 100
  ppc_prob_itr_end: 400  # 500  # 150  # 300  # 1300
  ppc_prob_val_ini: 1.0
  ppc_prob_val_end: 1.0  # 0.2  # 0.3
  use_timeouts: True
  use_track_curriculum: True
  #[posx, posy, theta, vellong, vellat, dtheta, steer]
  resetrand:  [0.05, 0.05, 0.05, 0.1, 0.01, 0.01, 0.0]  # [0.05, 0.05, 0.5, 2.0, 0.01,  0.5, 0.0]  # [0.05, 0.05, 0.9, 4.0, 0.01,  1.1, 0.0]
  #resetrand: [0.00, 0.0, 0., 0.0, 0.0,  0., 0.0]
  reset_tile_rand: 180
  resetgrid: True
  defaultactions: [0.0, 2.0]  # [0.0, 1.5]  # [0.0, 2.0]  # 04/13/2023: [0.0, 1.5]         # [0., 0.5, 0.0]
  actionscale: [1.0, 2.3]  # [1.0, 2.3]  # [1.0, 3.0]  # 04/13/2023: [1.0, 2.3]         # [0.3, 1.0, 0.2]
  defaultactionshl: [0., 0., 0.5, 0.5]
  actionscalehl: [1.0, 1.0, 1.0, 1.0]
  actionsminhl: [3.0, -0.5, 0.1, 0.05]  # [3.0, -0.55, 0.1, 0.1]  # [4.0, -0.55, 0.1, 0.05]  # [3.0, -0.6, 0.1, 0.1]
  actionsmaxhl: [6.0, +0.5, 0.5, 0.3]  # [7.0, +0.55, 0.5, 0.3]  # [6.0, +0.55, 0.5, 0.3]  # [5.0, +0.6, 0.7, 0.7]
  actionsinihl: [+0.0, +0.0, 0.5, 0.5]

  actionsallhl: [[+3.00, +4.00, +5.00, +6.00, +7.00],
                #  [+1.50, +2.00, +2.50, +3.00, +3.50],
                #  [+3.00, +4.00, +5.00, +6.00, +7.00],  # --> NOTE: switched to these instead of linear interpolation 
                 [-0.50, -0.25, +0.00, +0.25, +0.50],
                 [+0.05, +0.10, +0.20, +0.40, +0.80],
                 [+0.05, +0.10, +0.20, +0.40, +0.80],]
  use_hl_uncertainty: True

  agent_dropout_prob_val_ini: 1.0
  agent_dropout_prob_val_end: 0.0
  agent_dropout_prob_itr_ini: 0  # 50  # 1000
  agent_dropout_prob_itr_end: 200  # 500 
  agent_dropout_egos: False
  distance_obs_cutoff: 3.0 #[m]
  race_length_laps: 1

  totalRewardScale: 0.1  # 1.0  # 1.0
  progressRewardScale: 1.0  # 0.0  # 1.0  # 1.0  # 2.0  # 0.1  # 0.0  # 1.0  # 10.0  # 1.0  # 10.0
  offtrackRewardScale: -0.02  # -2.0  # -2.0  # -1.0  # -0.2  # -0.2  # -1.0  # -0.1  # -0.1
  actionRateRewardScale: -0.002  # -0.2  # -0.1  # -0.01  # -0.1
  rankRewardScale: 2.0  # 0.02  # 0.01  # 1.0  # 5.0  # 2.0  # 1.0  # 1.0  # 5.0  # 5.0  # 1.0
  collisionRewardScale: -0.02  # -2.0  # -25.0  # -5.0  # -2.0  # -1.0  # -0.2  #-0.2  # -0.02  # -0.2
  rearendcollisionRewardScale: -0.03  # -3.0
  accRewardScale: -0.001  # -0.1  # -0.5
  velRewardScale: -0.02  # -2.0  # -1.0
  goalRewardScale: 5.0  # 5.0  # 500.0  # 5.0  # 2.0  # 1.0  # 1.0  # 1.0  # 5.0  # NOTE: no *dt prior to 04/26/2023
  horizon: 12  #  12  # 12  # 15

  trackPenaltyScaleIni: 0.2
  trackPenaltyScaleItr: 100

  episode_length_ll: 20  # 20  # 20  # low-level steps in high-level step

  timeout: 16.0  # 16.0  # 16.0  # 24.0  # 25.0 #[s]
  offtrack_reset: 0.5  # 0.5  # 0.5  # 1.0  # 0.8 #[s]

  vel_noise_scale: 1. #0.5
  track_boundary_noise_scale: 1. # 0.3
  ado_pos_noise_scale: 1. #0.5
  ado_rot_noise_scale: 1. #0.1
  ado_vel_noise_scale: 1. #0.1
  ado_angvel_noise_scale: 1. #0.1
  obs_noise_lvl: 0.005  # 0.005  # 1.0  # 1.0  # FIXME: change back?
